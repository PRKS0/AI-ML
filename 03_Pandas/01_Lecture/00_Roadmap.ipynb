{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880e7690",
   "metadata": {},
   "source": [
    "Okay, here's the list of Pandas topics for AI/ML, formatted as Markdown suitable for an IPython Notebook cell:\n",
    "\n",
    "# Pandas for AI/ML: A Learning Roadmap\n",
    "\n",
    "## I. Core Fundamentals (The Absolute Must-Knows)\n",
    "\n",
    "1.  **Introduction to Pandas Data Structures:**\n",
    "    *   **Series:** Understand what a 1D labeled array is, how to create it, basic operations.\n",
    "    *   **DataFrame:** The 2D labeled data structure. This is your primary tool.\n",
    "        *   Creating DataFrames (from dictionaries, lists of lists, NumPy arrays, other DataFrames).\n",
    "2.  **Data Loading & Saving:**\n",
    "    *   **Reading Data:**\n",
    "        *   `pd.read_csv()` (most common): Key parameters like `sep`, `header`, `index_col`, `usecols`, `dtype`, `parse_dates`, `na_values`.\n",
    "        *   `pd.read_excel()`: For Excel files.\n",
    "        *   `pd.read_sql()`: For reading from databases (important for real-world projects).\n",
    "        *   (Less common but good to know they exist: `read_json`, `read_html`, `read_pickle`).\n",
    "    *   **Writing Data:**\n",
    "        *   `df.to_csv()`: Key parameters like `index`, `header`, `sep`.\n",
    "        *   `df.to_excel()`, `df.to_pickle()`.\n",
    "3.  **Data Inspection & Basic Exploration (EDA - Exploratory Data Analysis):**\n",
    "    *   `df.head()`, `df.tail()`: View first/last N rows.\n",
    "    *   `df.info()`: Get a concise summary (dtypes, non-null counts, memory usage). Crucial for understanding your data.\n",
    "    *   `df.describe()`: Get descriptive statistics (count, mean, std, min, max, quartiles). Very useful for numerical features.\n",
    "    *   `df.shape`: Get dimensions (rows, columns).\n",
    "    *   `df.dtypes`: Check data types of each column.\n",
    "    *   `df.columns`: Get column names.\n",
    "    *   `df.index`: Get index information.\n",
    "    *   `df.isnull().sum()` or `df.isna().sum()`: Count missing values per column (VERY important for ML).\n",
    "    *   `df.nunique()`: Count unique values per column.\n",
    "    *   `df['column_name'].value_counts()`: Get frequency counts for categorical features.\n",
    "\n",
    "## II. Data Selection & Indexing (Accessing the Data You Need)\n",
    "\n",
    "1.  **Selecting Columns:**\n",
    "    *   `df['column_name']` (returns a Series)\n",
    "    *   `df[['col1', 'col2']]` (returns a DataFrame)\n",
    "2.  **Selecting Rows (and Columns) with `loc` and `iloc`:**\n",
    "    *   **`df.loc[]` (Label-based indexing):**\n",
    "        *   `df.loc[row_label]`, `df.loc[row_label, column_label]`\n",
    "        *   Slicing: `df.loc[start_label:end_label, start_col:end_col]`\n",
    "        *   Boolean indexing: `df.loc[df['column'] > value]` (EXTREMELY powerful for filtering)\n",
    "    *   **`df.iloc[]` (Integer-position based indexing):**\n",
    "        *   `df.iloc[row_position]`, `df.iloc[row_position, col_position]`\n",
    "        *   Slicing: `df.iloc[start_pos:end_pos, start_col_pos:end_col_pos]`\n",
    "3.  **Conditional Selection (Boolean Indexing):**\n",
    "    *   `df[df['column'] > value]`\n",
    "    *   Combining conditions: `df[(df['col1'] > value1) & (df['col2'] == value2)]` (use `&` for AND, `|` for OR, `~` for NOT, and wrap conditions in parentheses).\n",
    "\n",
    "## III. Data Cleaning & Preprocessing (Critical for ML)\n",
    "\n",
    "1.  **Handling Missing Data:**\n",
    "    *   Identifying: `df.isnull()`, `df.isna()`.\n",
    "    *   Dropping: `df.dropna()` (parameters `axis`, `how`, `thresh`, `subset`).\n",
    "    *   Filling/Imputing: `df.fillna()` (with a constant, mean, median, mode, `ffill`, `bfill`).\n",
    "2.  **Handling Duplicates:**\n",
    "    *   `df.duplicated()`: Identify duplicate rows.\n",
    "    *   `df.drop_duplicates()`: Remove duplicate rows (parameters `subset`, `keep`).\n",
    "3.  **Changing Data Types:**\n",
    "    *   `df['column'].astype()`: e.g., `astype(int)`, `astype(float)`, `astype(str)`, `astype('category')`. Important for memory optimization and model compatibility.\n",
    "4.  **String Operations (for text features):**\n",
    "    *   The `.str` accessor: `df['text_column'].str.lower()`, `.str.upper()`, `.str.contains()`, `.str.replace()`, `.str.split()`, `.str.strip()`.\n",
    "5.  **Applying Functions:**\n",
    "    *   `df.apply()`: Apply a function along an axis (rows or columns).\n",
    "    *   `df['column'].apply()` or `df['column'].map()`: Apply a function element-wise to a Series.\n",
    "    *   `df.applymap()`: Apply a function element-wise to the entire DataFrame (less common for specific ML tasks, more for general transformations).\n",
    "    *   Using lambda functions for quick transformations.\n",
    "\n",
    "## IV. Data Transformation & Feature Engineering (The Heart of Pandas for ML)\n",
    "\n",
    "1.  **Adding/Modifying Columns:**\n",
    "    *   Direct assignment: `df['new_column'] = ...`\n",
    "    *   Using existing columns: `df['new_column'] = df['col1'] + df['col2']`\n",
    "    *   `df.assign()`: Create new columns in a chainable way.\n",
    "2.  **Grouping and Aggregation (`groupby`):**\n",
    "    *   `df.groupby('column_name')`: Create a GroupBy object.\n",
    "    *   Applying aggregation functions: `.sum()`, `.mean()`, `.median()`, `.min()`, `.max()`, `.count()`, `.std()`, `.var()`, `.size()`.\n",
    "    *   `df.groupby('column_name').agg({'col_to_agg': ['mean', 'sum']})`: Multiple aggregations.\n",
    "    *   `df.groupby(['col1', 'col2'])`: Grouping by multiple columns.\n",
    "    *   Creating features based on group statistics (e.g., average purchase amount per customer).\n",
    "3.  **Merging, Joining, and Concatenating DataFrames:**\n",
    "    *   **`pd.concat([df1, df2])`**: Stacking DataFrames (along `axis=0` or `axis=1`).\n",
    "    *   **`pd.merge(df1, df2, on='key_column', how='inner')`**: SQL-like joins.\n",
    "        *   Understand `how` parameter: `'inner'`, `'outer'`, `'left'`, `'right'`.\n",
    "        *   `left_on`, `right_on` for different key column names.\n",
    "    *   `df.join()`: Index-based joining.\n",
    "4.  **Pivoting and Reshaping Data:**\n",
    "    *   `df.pivot_table()`: Create a spreadsheet-style pivot table (very useful for summarizing and creating features). Key parameters: `values`, `index`, `columns`, `aggfunc`.\n",
    "    *   `pd.melt()`: Unpivot a DataFrame from wide to long format.\n",
    "    *   `df.stack()`, `df.unstack()`: For reshaping with MultiIndex.\n",
    "5.  **Binning/Discretization (Converting continuous to categorical):**\n",
    "    *   `pd.cut()`: Bin values into discrete intervals based on specified bins.\n",
    "    *   `pd.qcut()`: Bin values into equal-sized buckets based on rank or sample quantiles.\n",
    "6.  **Working with Categorical Data:**\n",
    "    *   `pd.Categorical()` or `astype('category')`: For memory efficiency and enabling certain statistical operations.\n",
    "    *   `pd.get_dummies()`: One-Hot Encoding (converting categorical variables into numerical format for ML models).\n",
    "\n",
    "## V. Time Series Analysis (If your data has a time component)\n",
    "\n",
    "1.  **Datetime Objects:**\n",
    "    *   `pd.to_datetime()`: Converting strings/columns to datetime objects.\n",
    "    *   `.dt` accessor: `df['date_col'].dt.year`, `.dt.month`, `.dt.day`, `.dt.dayofweek`, `.dt.hour`, etc. (Feature Engineering!)\n",
    "2.  **Time-based Indexing and Selection:**\n",
    "    *   Setting a DatetimeIndex: `df.set_index('date_col')`.\n",
    "    *   Slicing by date/time ranges.\n",
    "3.  **Resampling:**\n",
    "    *   `df.resample('D').mean()`: Downsampling (e.g., daily to monthly) or upsampling.\n",
    "4.  **Rolling Windows (Moving Averages/Statistics):**\n",
    "    *   `df['column'].rolling(window=N).mean()`: Calculate rolling mean, sum, std, etc. (Feature Engineering for trends).\n",
    "5.  **Shifting/Lagging:**\n",
    "    *   `df['column'].shift(N)`: Create lagged features (yesterday's value, etc.).\n",
    "\n",
    "## VI. Performance and Best Practices\n",
    "\n",
    "1.  **Vectorization:** Prioritize vectorized operations (Pandas/NumPy functions) over Python loops for speed.\n",
    "2.  **Efficient Data Types:** Use `category` for low-cardinality strings, appropriate integer/float sizes.\n",
    "3.  **Method Chaining:** Writing sequences of operations in a single, readable line.\n",
    "4.  **Copy vs. View (`SettingWithCopyWarning`):** Understand when Pandas returns a copy vs. a view to avoid unexpected behavior. Use `.copy()` explicitly when modifying subsets if you want to avoid changing the original DataFrame.\n",
    "\n",
    "## What to Focus On for AI/ML\n",
    "\n",
    "*   **Data Cleaning (Missing Values, Duplicates):** Your models will perform poorly with messy data.\n",
    "*   **Feature Engineering (Groupby, Apply, Merging, Binning, Datetime features):** This is where you create signals for your model. Good features are more important than complex models.\n",
    "*   **Data Selection & Filtering (`loc`, `iloc`, Boolean Indexing):** Essential for isolating data subsets for analysis or training.\n",
    "*   **One-Hot Encoding (`get_dummies`):** Standard way to prepare categorical data for most ML algorithms.\n",
    "*   **Understanding `df.info()` and `df.describe()`:** Quick first steps to understand any dataset.\n",
    "\n",
    "## What NOT to Focus On (Initially)\n",
    "\n",
    "*   **Deep dive into MultiIndex complexity:** Understand the basics of how it's created (e.g., via `groupby` multiple columns or `pivot_table`), but don't get bogged down in advanced manipulation unless a specific problem requires it.\n",
    "*   **Advanced Plotting within Pandas:** Pandas has basic plotting (`df.plot()`), but for serious visualizations, you'll likely use Matplotlib, Seaborn, or Plotly. Focus on data manipulation first.\n",
    "*   **Highly specialized file formats:** Stick to CSV, Excel, SQL initially.\n",
    "*   **Extremely large dataset tools (like Dask or Koalas for Spark):** Master Pandas first. If you hit performance walls with very large data, then explore these.\n",
    "*   **Writing highly complex custom classes that interact with Pandas internals.**\n",
    "\n",
    "## Learning Strategy\n",
    "\n",
    "1.  **Hands-on Practice:** The most important thing. Don't just read; code along.\n",
    "2.  **Use Real (or Realistic) Datasets:** Kaggle is a great source for datasets.\n",
    "3.  **Start with a Small Project:** e.g., \"Load this CSV, clean missing values, calculate some group statistics, and create a new feature.\"\n",
    "4.  **Refer to the Pandas Documentation:** It's excellent and very comprehensive.\n",
    "5.  **Ask Questions:** Stack Overflow has answers to almost any Pandas question you can think of.\n",
    "\n",
    "This list should give you a solid roadmap. Good luck, and enjoy the power of Pandas!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
